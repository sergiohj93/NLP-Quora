{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cdfcff6f-9c77-43d3-be15-c2a3dd9886c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2fcac3-f041-4613-bd86-f2e0fb1d18c1",
   "metadata": {},
   "source": [
    "# Simple model functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2094e3d7-266c-4ed0-9df3-16f8544a3e2c",
   "metadata": {},
   "source": [
    "We have created the simple model following the preparation notebook `delivery_1_quora.ipynb`. So, we have included in our `utils.py` the functions from that notebook, needed to create the count vectorizer model (including the casting preprocessing and the mistakes testing). \n",
    "\n",
    "`cast_list_as_strings` is explained in the following section (Preprocessing functions), because we also use it with the improved model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d8f855-81cd-43a3-8a4e-20dedeb08b0c",
   "metadata": {},
   "source": [
    "# Preprocess functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f5384c-df11-4fcb-8eaa-1a3c017b054d",
   "metadata": {},
   "source": [
    "All these preprocess functions are meant to receive a list of strings (representing sentences), and apply some transformation to each string/sentence.\n",
    "\n",
    "We use them to preprocess one question field. So, to consider both question1 and question2 (of training, validation or test sets), we have to call the functions many times.\n",
    "\n",
    "In order to show their usage, we are going to consider two rows of our training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aca29928-aa0d-4f10-9e7f-c52a92e33102",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions1 = [\"How do you convert direct speech into reported speech and vice versa including all cases?\", \"Where can I buy used wine barrels?\"]\n",
    "questions2 = [\"I feel weak at spoken English. I have sentences ready in my mind, but I can't speak it. What should I do?\", \"Where can you buy used wine barrels?\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5717ef8-b100-4fde-95d6-92a635037fe5",
   "metadata": {},
   "source": [
    "## cast_list_as_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1dc4cac4-3087-4390-8740-7a9a0573f74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cast_list_as_strings(mylist):\n",
    "    mylist_of_strings = []\n",
    "    for x in mylist:\n",
    "        mylist_of_strings.append(str(x))\n",
    "    return mylist_of_strings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e38aad-611b-44d2-a746-12b33d4f08b3",
   "metadata": {},
   "source": [
    "Cast each string/sentence of the list to a string. This is done to solve the problem of having another type of data, as floats, for example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54153e91-5363-4e87-b785-15f26254596d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Questions 1: ['How do you convert direct speech into reported speech and vice versa including all cases?', 'Where can I buy used wine barrels?']\n",
      "Questions 2: [\"I feel weak at spoken English. I have sentences ready in my mind, but I can't speak it. What should I do?\", 'Where can you buy used wine barrels?']\n"
     ]
    }
   ],
   "source": [
    "questions1_casted = cast_list_as_strings(questions1)\n",
    "questions2_casted = cast_list_as_strings(questions2)\n",
    "print(\"Questions 1:\",questions1_casted)\n",
    "print(\"Questions 2:\",questions2_casted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510964e3-365f-484e-bb86-4d1b2a54093a",
   "metadata": {},
   "source": [
    "## lower_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ac15d70-215b-42b2-9de5-549f956e3410",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lower_list(mylist):\n",
    "    list_lowered = []\n",
    "    for string in mylist:\n",
    "        list_lowered.append(string.lower())\n",
    "    return list_lowered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79edbf33-efea-45dc-93d4-b7cfb98d7234",
   "metadata": {},
   "source": [
    "Lows each string/sentence of the list, in order to not have differences between lower and upper case letters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9efd945-03e7-40f1-a845-ef260e76041d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Questions 1: ['how do you convert direct speech into reported speech and vice versa including all cases?', 'where can i buy used wine barrels?']\n",
      "Questions 2: [\"i feel weak at spoken english. i have sentences ready in my mind, but i can't speak it. what should i do?\", 'where can you buy used wine barrels?']\n"
     ]
    }
   ],
   "source": [
    "questions1_lw = lower_list(questions1_casted)\n",
    "questions2_lw = lower_list(questions2_casted)\n",
    "print(\"Questions 1:\",questions1_lw)\n",
    "print(\"Questions 2:\",questions2_lw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9afd043-1916-45d3-86e4-2189d596dc94",
   "metadata": {},
   "source": [
    "## remove_sw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "152d52f9-b71b-4261-a92a-b15b9a0ea3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_sw(mylist,stop_words):\n",
    "    list_without_sw = []\n",
    "    for string in mylist:\n",
    "        # Pattern to match stop words\n",
    "        pattern = re.compile(r'\\b(' + '|'.join(stop_words) + r')\\b')\n",
    "        # Remove the stop words using the regular expression pattern\n",
    "        list_without_sw.append(pattern.sub('',string))\n",
    "    return list_without_sw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e235b62-157b-48cf-8480-d14d3cadab68",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = [\"a\", \"an\", \"the\", \"and\", \"but\", \"or\", \"in\", \"on\", \"at\", \"to\", \"of\", \"for\",\"i\",\"you\",\"he\",\"she\",\"it\",\"we\",\"they\",\n",
    "             \"me\",\"him\",\"her\",\"us\",\"them\",\"my\",\"your\",\"his\",\"its\",\"our\",\"their\",\"mine\",\"yours\",\"hers\",\"ours\",\"theirs\",\"myself\",\n",
    "              \"yourself\",\"himself\",\"herself\",\"itself\",\"ourselves\",\"yourselves\",\"themselves\",\"this\",\"that\",\"these\",\"those\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3970fd4-828f-431c-8a7c-90697b83b3f9",
   "metadata": {},
   "source": [
    "Given a list of stop words, the regular expression pattern allows us to remove all that words for each string/sentence of the list. These words don't carry much meaning and can make two questions more different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c5a0b62-a1ca-4edf-937c-e1327c339bb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Questions 1: ['how do  convert direct speech into reported speech  vice versa including all cases?', 'where can  buy used wine barrels?']\n",
      "Questions 2: [\" feel weak  spoken english.  have sentences ready   mind,   can't speak . what should  do?\", 'where can  buy used wine barrels?']\n"
     ]
    }
   ],
   "source": [
    "questions1_sw = remove_sw(questions1_lw,stop_words)\n",
    "questions2_sw = remove_sw(questions2_lw,stop_words)\n",
    "print(\"Questions 1:\",questions1_sw)\n",
    "print(\"Questions 2:\",questions2_sw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8530ed-0f0c-40b9-b563-777823b85677",
   "metadata": {},
   "source": [
    "## tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a2ba626-5b1f-4c21-adaa-4b8eb763f77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(mylist):\n",
    "    list_tokenized = []\n",
    "    for string in mylist:\n",
    "        # Regular expression pattern to match words\n",
    "        pattern = re.compile(r\"\\w+\")\n",
    "        tokens = pattern.findall(string)\n",
    "        list_tokenized.append(tokens)\n",
    "    return list_tokenized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3817aff7-1a79-4aab-bf51-9b87c6d9f81e",
   "metadata": {},
   "source": [
    "Obtains words (a list of strings) for each string/sentence of the list. The regular expression pattern used also considers numbers as words. Although the similarity between near numbers cannot be captured, we think that considering numbers in this \"questions comparison\" scenario could make sense because two equivalent questions should ask about the exact same number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53c2c6e7-d467-420c-8e00-56760f9950d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Questions 1: [['how', 'do', 'convert', 'direct', 'speech', 'into', 'reported', 'speech', 'vice', 'versa', 'including', 'all', 'cases'], ['where', 'can', 'buy', 'used', 'wine', 'barrels']]\n",
      "Questions 2: [['feel', 'weak', 'spoken', 'english', 'have', 'sentences', 'ready', 'mind', 'can', 't', 'speak', 'what', 'should', 'do'], ['where', 'can', 'buy', 'used', 'wine', 'barrels']]\n"
     ]
    }
   ],
   "source": [
    "questions1_tokens = tokenize(questions1_sw)\n",
    "questions2_tokens = tokenize(questions2_sw)\n",
    "print(\"Questions 1:\",questions1_tokens)\n",
    "print(\"Questions 2:\",questions2_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2142234a-fc19-434d-a6e0-a55fff34c23f",
   "metadata": {},
   "source": [
    "# Jaccard distance functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34abe674-85cb-41cf-aeb4-eca49a6fa3de",
   "metadata": {},
   "source": [
    "As a feature for the improved model, we consider the jaccard distance at sentence level. We implement it and obtain the feature with the following functions:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490b947a-fe0e-482f-ab33-9ac0e73e312f",
   "metadata": {},
   "source": [
    "## jaccard_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c25450a-3556-4349-a670-1a8e13cd940b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_similarity(sent1,sent2):\n",
    "    return len(sent1.intersection(sent2)) / len(sent1.union(sent2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57459a38-948f-46aa-8a7c-db5c4499245b",
   "metadata": {},
   "source": [
    "Calculates the jaccard similarity between the tokens of two sentences. The number of elements of the intersection divided by the number of elements of the union."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3deda6dd-a0ba-4dad-b31d-2262403f5bda",
   "metadata": {},
   "source": [
    "## jaccard_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "56e1296c-cb9b-4fcd-a449-e9c094548021",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_distance(sent1,sent2):\n",
    "    return 1-jaccard_similarity(sent1,sent2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42fb8e8-237e-4065-b98f-f1c123301bed",
   "metadata": {},
   "source": [
    "It substracts the jaccard similarity to 1 in order to obtain the jaccard distance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac434f9-f068-4e76-868f-d913544e9dc9",
   "metadata": {},
   "source": [
    "## generate_jd_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e3f81379-0a20-4a51-9d86-1bedff03179e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_jd_feature(q1_tokens,q2_tokens):\n",
    "    jd_feature = []\n",
    "    for i in range(len(q1_tokens)):\n",
    "        jd = jaccard_distance(set(q1_tokens[i]),set(q2_tokens[i]))\n",
    "        jd_feature.append(jd)\n",
    "    return jd_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e60a41-14ee-475c-9cf2-c7323551e2a0",
   "metadata": {},
   "source": [
    "Given a list of tokenized sentences for both question 1 and 2, this function calculates the jaccard distance between each pair of sentences. It will be the jaccard distance feature that we use in our improved model. To show their usage, we apply it to the previously tokenized sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fcbe6fff-8e20-4d9f-99cf-a9404802cc15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Questions 1: [['how', 'do', 'convert', 'direct', 'speech', 'into', 'reported', 'speech', 'vice', 'versa', 'including', 'all', 'cases'], ['where', 'can', 'buy', 'used', 'wine', 'barrels']]\n",
      "Questions 2: [['feel', 'weak', 'spoken', 'english', 'have', 'sentences', 'ready', 'mind', 'can', 't', 'speak', 'what', 'should', 'do'], ['where', 'can', 'buy', 'used', 'wine', 'barrels']]\n"
     ]
    }
   ],
   "source": [
    "print(\"Questions 1:\",questions1_tokens)\n",
    "print(\"Questions 2:\",questions2_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "18be7468-277e-4df4-ad59-d2246ac97908",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.96, 0.0]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_jd_feature(questions1_tokens,questions2_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b226dca7-ccd9-45ce-afd2-a95f0e5e4181",
   "metadata": {},
   "source": [
    "After the preprocess and tokenization, the second pair of questions has become equal. For this reason, the jaccard distance is 0. But, in the first pair, there are almost any coincidence, so the distance is high. And indeed, the target feature of the second pair indicates that they are duplicate, while the target of the first pair indicates the opposite."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972f4fd5-a024-46a8-a893-2b2b433933ff",
   "metadata": {},
   "source": [
    "# Evaluation functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff890fff-17e4-429a-bd7c-35b691aa8b8a",
   "metadata": {},
   "source": [
    "## calculate_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "890fefdf-3079-4c7d-8a01-9484bb4e1b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(y,X,model):\n",
    "    model_metrics = []\n",
    "    model_metrics.append(metrics.roc_auc_score(y,model.predict(X)))\n",
    "    model_metrics.append(metrics.accuracy_score(y,model.predict(X)))\n",
    "    model_metrics.append(metrics.precision_score(y,model.predict(X)))\n",
    "    model_metrics.append(metrics.recall_score(y,model.predict(X)))\n",
    "    model_metrics.append(metrics.f1_score(y,model.predict(X)))\n",
    "    return model_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44cbd554-6a04-4f42-ad78-e0618fff1f6e",
   "metadata": {},
   "source": [
    "Given a trained model and the features obtained from one of the datasets (train, validation, test), it calculates the roc auc, accuracy, precision, recall and f1 score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f820d880-11cb-41f9-aa12-064d301ca0c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
